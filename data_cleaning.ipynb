{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............SEPARATING DATE AND TIME FROM RAW DATA...........\n",
      "\n",
      "\n",
      "[['20190620', '032717'], ['20190620', '052652'], [nan, nan], ['20190620', '052735']]\n"
     ]
    }
   ],
   "source": [
    "# SEPARATES THE DATE AND TIME\n",
    "def datetime_divider(data):\n",
    "    for index in range(len(data)):\n",
    "        # find the digit if at begining only not others\n",
    "        if re.match(\"^\\d\", str(data[index])):\n",
    "            regex = re.compile(\"\\d{1,8}\")\n",
    "            a = regex.findall(str(data[index]))\n",
    "            data[index] = [a[0], a[1]]\n",
    "        else:\n",
    "            data[index] = [np.nan, np.nan]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [\"20190620032717.906\", \"20190620052652.52\", '', \"20190620052735.207\"]\n",
    "print(\"\\n\\n.............SEPARATING DATE AND TIME FROM RAW DATA...........\\n\\n\")\n",
    "print(datetime_divider(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT MODIFIES THE DATE IN YYYY-MM-DD FORMAT\n",
    "def date_modifier(data):\n",
    "    for i in range(len(data)):\n",
    "        if (re.match(\"^\\d\", str(data[i]))):\n",
    "            year = str(data[i])[:4]\n",
    "            month = str(data[i])[4:6]\n",
    "            date = str(data[i])[6:]\n",
    "            data[i] = \"-\".join([year, month, date])\n",
    "        else:\n",
    "            data[i] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['20190620', '20190620', np.nan, '20190620']\n",
    "print(\"\\n\\n.............IN STANDARD DATE FORMAT...........\\n\\n\")\n",
    "print(date_modifier(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT MODIFIES TIME IN HH-MM-SS FORMAT\n",
    "def time_modifier(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = str(data[i])\n",
    "        if re.match(\"^\\d\", data[i]):\n",
    "            hour = data[i][0:2]\n",
    "            min = data[i][2:4]\n",
    "            sec = data[i][4:]\n",
    "            meridian = None\n",
    "            hr = int(hour)\n",
    "            if (hr >= 12):\n",
    "                if hr == 12:\n",
    "                    hour = str(12)\n",
    "                else:\n",
    "                    hour = str(hr - 12)\n",
    "                meridian = \"PM\"\n",
    "            else:\n",
    "                if hr == 0:\n",
    "                    hour = str(12)\n",
    "                else:\n",
    "                    hour = str(hr)\n",
    "                meridian = \"AM\"\n",
    "            data[i] = f\"{hour}-{min}-{sec} {meridian}\"\n",
    "        else:\n",
    "            data[i] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "time_data = ['032717', '202652', np.nan, '052735', '003419']\n",
    "print(\"\\n\\n.............IN STANDARD TIME FORMAT...........\\n\\n\")\n",
    "print(time_modifier(time_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW CLEANING THE DATA FROM THE CDR SHEET\n",
    "\n",
    "dataset_name = \"raw_cdr_data.csv\"\n",
    "dataframe = pd.read_csv(dataset_name, header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACING SIMPLE TERMINOLOGY WITH STANDARD TERMS\n",
    "\n",
    "def replacing_simple_teminology_with_standard(dataframe):\n",
    "    dataframe[5] = dataframe[5].replace('Originating', 'Outgoing')\n",
    "    dataframe[5] = dataframe[5].replace('Terminating', 'Incoming')\n",
    "    dataframe[267] = dataframe[267].replace('Success', 'Voice Portal')\n",
    "    dataframe[312] = dataframe[312].replace('Shared Call Appearance', 'Secondary Device')\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "dataframe = replacing_simple_teminology_with_standard(dataframe)\n",
    "print(\"\\n\\n.............REPLACING SIMPLE TERMINOLOGY WITH STANDARD TERMS...........\\n\\n\")\n",
    "print(dataframe[5].unique())\n",
    "print(dataframe[267].unique())\n",
    "print(dataframe[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING UNWANTED DATA FROM CDR SHEET\n",
    "\n",
    "def remove_unwanted_data(datacolumn):\n",
    "    for i in range(len(datacolumn)):\n",
    "        if datacolumn[i] == ('Secondary Device') or datacolumn[i] == ('Primary Device'):\n",
    "            continue\n",
    "        else:\n",
    "            datacolumn[i] = np.nan\n",
    "    return datacolumn\n",
    "\n",
    "\n",
    "dataframe[312] = remove_unwanted_data(dataframe[312].tolist())\n",
    "print(\"\\n\\n.............REMOVING UNWANTED TERMS FROM COLUMN 312...........\\n\\n\")\n",
    "print(dataframe[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINIG ALL THE SERVICES\n",
    "\n",
    "def combine_all_services(datacolumn147, datacolumn312, datacolumn267):\n",
    "    for index in range(len(datacolumn147)):\n",
    "        if (datacolumn147[index] is np.nan):\n",
    "            if (datacolumn312[index] is not np.nan and datacolumn267[index] is not np.nan):\n",
    "                datacolumn147[index] = str(datacolumn312[index]) + \" , \" + str(datacolumn267[index])\n",
    "            elif (datacolumn312[index] is not np.nan):\n",
    "                datacolumn147[index] = datacolumn312[index]\n",
    "            else:\n",
    "                datacolumn147[index] = datacolumn267[index]\n",
    "        else:\n",
    "            continue\n",
    "    return datacolumn147\n",
    "\n",
    "\n",
    "dataframe[147] = combine_all_services(dataframe[147].tolist(), dataframe[312].tolist(), dataframe[267].tolist())\n",
    "print(\"\\n\\n.............COMBINING ALL THE SERVICES IN COL 312,147,267...........\\n\\n\")\n",
    "print(dataframe[147].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT DATE-TIME DATA INTO SPCIFIC FORMAT\n",
    "def call_time_fetcher(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            year = data[index][0:4]\n",
    "            month = data[index][4:6]\n",
    "            day = data[index][6:8]\n",
    "            hour = data[index][8:10]\n",
    "            minute = data[index][10:12]\n",
    "            seconds = str(round(float(data[index][12:])))\n",
    "\n",
    "            if int(seconds) >= 60:\n",
    "                seconds = int(seconds) - 60\n",
    "                minute = int(minute) + 1\n",
    "            if int(minute) >= 60:\n",
    "                minute = int(minute) - 1\n",
    "                hour = int(hour) + 1\n",
    "            data[index] = f\"{year}-{month}-{day}  {hour}:{minute}:{seconds}\"\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [\"20190620032717.906\", \"20190621132819.68\", 'nan', \"20190625192352.293\"]\n",
    "print(\"\\n\\n...........CONVERT DATE-TIME DATA INTO SPCIFIC FORMAT............\\n\\n\")\n",
    "print(call_time_fetcher(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDING THE HOURLY RANGE\n",
    "def hourly_range(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            if re.search(\"PM\", data[index]):\n",
    "                time_data = re.findall(\"\\d+\", data[index])\n",
    "                if time_data[0] != \"12\":\n",
    "                    time_data = int(time_data[0]) + 12\n",
    "                else:\n",
    "                    time_data = time_data[0]\n",
    "            else:\n",
    "                time_data = re.findall(\"\\d+\", data[index])\n",
    "                if time_data[0] == \"12\":\n",
    "                    time_data = int(time_data[0]) - 12\n",
    "                else:\n",
    "                    time_data = time_data[0]\n",
    "            data[index] = f\"{time_data}:00 - {time_data}:59\"\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['3:27:17 AM', '1:28:19 PM', 'nan', '7:23:52 PM', '12:20:45 AM', '12:56:27 PM']\n",
    "print(\"\\n\\n...........FINDING HOURLY RANGE............\\n\\n\")\n",
    "print(hourly_range(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINDING THE WEEKLY RANGE\n",
    "def weekly_range(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            year, month, date = (int(x) for x in data[index].split(\"-\"))\n",
    "            result = datetime.date(year, month, date)\n",
    "            data[index] = result.strftime(\"%A\")\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['2019-06-20', '2019-06-21', 'nan', '2019-06-25', '2020-11-06']\n",
    "print(\"\\n\\n...........FINDING WEEKLY RANGE............\\n\\n\")\n",
    "print(weekly_range(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Number of functions made\n",
    "1. datetime_divider()\n",
    "2. date_modifier()\n",
    "3. time_modifier()\n",
    "4. replacing_simple_teminology_with_standard()\n",
    "5. remove_unwanted_data()\n",
    "6. combine_all_services()\n",
    "7. call_time_fetcher()\n",
    "8. hourly_range()\n",
    "9. weekly_range()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n...........NOW CREATING NEW COLUMNS WITH CLEANED DATA............\\n\\n\")\n",
    "dataset_name = \"raw_cdr_data.csv\"\n",
    "raw_cdr_data = pd.read_csv(dataset_name, header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE 2 COLUMNS TO STORE DATE AND TIME\n",
    "raw_cdr_data['date'], raw_cdr_data['time'] = zip(*datetime_divider(raw_cdr_data[9].tolist()))\n",
    "\n",
    "print(raw_cdr_data['date'].tolist()[0])\n",
    "print(raw_cdr_data['time'].tolist()[0])\n",
    "\n",
    "raw_cdr_data['date'] = date_modifier(raw_cdr_data['date'].tolist())\n",
    "raw_cdr_data['time'] = time_modifier(raw_cdr_data['time'].tolist())\n",
    "\n",
    "print(raw_cdr_data['date'].tolist()[0])\n",
    "print(raw_cdr_data['time'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING A NEW COLUMN WITH STANDARD TERMINOLOGIES\n",
    "raw_cdr_data = replacing_simple_teminology_with_standard(raw_cdr_data)\n",
    "print(raw_cdr_data[5])\n",
    "print(raw_cdr_data[267].unique())\n",
    "print(raw_cdr_data[312])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Primary Device']\n"
     ]
    }
   ],
   "source": [
    "# NOW REMOVING UNWANTED DATA FROM 312\n",
    "raw_cdr_data[312] = remove_unwanted_data(raw_cdr_data[312].tolist())\n",
    "print(raw_cdr_data[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW COMBINING DATA OF COLUMN 312 , 267 , 147\n",
    "raw_cdr_data[147] = combine_all_services(raw_cdr_data[147].tolist(), raw_cdr_data[312].tolist(), raw_cdr_data[267].tolist())\n",
    "print(raw_cdr_data[147].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW MAKING 2 TEMPORARY COLUMNS FOR CALCULATING THE CALL DURATION\n",
    "raw_cdr_data['starttime'] = pd.to_datetime(call_time_fetcher(raw_cdr_data[9].tolist()))\n",
    "print(raw_cdr_data['starttime'])\n",
    "raw_cdr_data['endtime'] = pd.to_datetime(call_time_fetcher(raw_cdr_data[13].tolist()))\n",
    "print(raw_cdr_data['endtime'])\n",
    "\n",
    "raw_cdr_data[\"duration\"] = (raw_cdr_data[\"endtime\"] - raw_cdr_data[\"starttime\"]).astype(\"timedelta64[m]\")\n",
    "print(raw_cdr_data[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW CREATING 2 COLUMNS FOR HOURLY RANGE AND WEEKLY RANGE\n",
    "raw_cdr_data['hourly_range'] = hourly_range(raw_cdr_data['time'].tolist())\n",
    "print(raw_cdr_data['hourly_range'])\n",
    "\n",
    "raw_cdr_data['weekly_range'] = weekly_range(raw_cdr_data['date'].tolist())\n",
    "print(raw_cdr_data['weekly_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THE COLUMNS WHICH ARE NOT REQUIRED\n",
    "raw_cdr_data = raw_cdr_data.drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cdr_data.csv\"\n",
    "\n",
    "# Required columns\n",
    "call_columns = [\"4\", \"5\", \"14\", \"31\", \"120\", \"147\", \"267\", \"312\", \"345\", \\\n",
    "                \"date\", \"starttime\", \"endtime\", \"duration\", \"hourly_range\", \"weekly_range\"]\n",
    "\n",
    "call_dataset = pd.read_csv(dataset_name, usecols=call_columns, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR SERVICE DATA\n",
    "service_columns = ['31', '120', '147', '345', 'date', 'starttime', 'endtime', 'duration']\n",
    "service_dataset = call_dataset[service_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR DEVICE DATASET\n",
    "device_columns = ['5', '31', '120', '312', '345', 'date', 'starttime', 'endtime', 'duration']\n",
    "device_dataset = call_dataset[device_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAMING COLUMN NAMES AS PER CLIENT REQUIREMENT\n",
    "call_dataset = call_dataset.rename(columns={\"4\": \"Group\", \"5\": \"Call_Direction\", \"14\": \"Missed Calls\",\n",
    "                                            \"31\": \"GroupID\", \"120\": \"UserID\", \"147\": \"Features\",\n",
    "                                            \"267\": \" vpDialingfacResult\",\n",
    "                                            \"312\": \"UsageDeviceType\",\n",
    "                                            \"345\": \"UserDeviceType\"})\n",
    "\n",
    "service_dataset = service_dataset.rename(columns={\"120\": \"UserID\",\n",
    "                                                  \"31\": \"GroupID\", \"147\": \"FeatureName\",\n",
    "                                                  \"345\": \"UserDeviceType\", \"date\": \"FeatureEventDate\"\n",
    "                                                  })\n",
    "\n",
    "device_dataset = device_dataset.rename(columns={\"5\": \"DeviceEventTypeDirection\",\n",
    "                                                \"120\": \"UserID\", \"31\": \"GroupID\",\n",
    "                                                \"345\": \"UserDeviceType\", \"date\": \"DeviceEventDate\",\n",
    "                                                \"312\": \"UsageDeviceType\"})\n",
    "\n",
    "call_dataset.to_csv(\"Call_data.csv\", index=None)\n",
    "service_dataset.to_csv(\"Service_data.csv\", index=None)\n",
    "device_dataset.to_csv(\"Device_data.csv\", index=None)\n",
    "print(\"ALL THE CSV FILES ARE CREATED SUCCESSFULLY..........!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
