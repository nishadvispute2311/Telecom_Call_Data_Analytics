{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............SEPARATING DATE AND TIME FROM RAW DATA...........\n",
      "\n",
      "\n",
      "[['20190620', '032717'], ['20190620', '052652'], [nan, nan], ['20190620', '052735']]\n"
     ]
    }
   ],
   "source": [
    "# SEPARATES THE DATE AND TIME\n",
    "def datetime_divider(data):\n",
    "    for index in range(len(data)):\n",
    "        # find the digit if at begining only not others\n",
    "        if re.match(\"^\\d\", str(data[index])):\n",
    "            regex = re.compile(\"\\d{1,8}\")\n",
    "            a = regex.findall(str(data[index]))\n",
    "            data[index] = [a[0], a[1]]\n",
    "        else:\n",
    "            data[index] = [np.nan, np.nan]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [\"20190620032717.906\", \"20190620052652.52\", '', \"20190620052735.207\"]\n",
    "print(\"\\n\\n.............SEPARATING DATE AND TIME FROM RAW DATA...........\\n\\n\")\n",
    "print(datetime_divider(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............IN STANDARD DATE FORMAT...........\n",
      "\n",
      "\n",
      "['2019-06-20', '2019-06-20', nan, '2019-06-20']\n"
     ]
    }
   ],
   "source": [
    "# IT MODIFIES THE DATE IN YYYY-MM-DD FORMAT\n",
    "def date_modifier(data):\n",
    "    for i in range(len(data)):\n",
    "        if (re.match(\"^\\d\", str(data[i]))):\n",
    "            year = str(data[i])[:4]\n",
    "            month = str(data[i])[4:6]\n",
    "            date = str(data[i])[6:]\n",
    "            data[i] = \"-\".join([year, month, date])\n",
    "        else:\n",
    "            data[i] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['20190620', '20190620', np.nan, '20190620']\n",
    "print(\"\\n\\n.............IN STANDARD DATE FORMAT...........\\n\\n\")\n",
    "print(date_modifier(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............IN STANDARD TIME FORMAT...........\n",
      "\n",
      "\n",
      "['3-27-17 AM', '8-26-52 PM', nan, '5-27-35 AM', '12-34-19 AM']\n"
     ]
    }
   ],
   "source": [
    "# IT MODIFIES TIME IN HH-MM-SS FORMAT\n",
    "def time_modifier(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = str(data[i])\n",
    "        if re.match(\"^\\d\", data[i]):\n",
    "            hour = data[i][0:2]\n",
    "            min = data[i][2:4]\n",
    "            sec = data[i][4:]\n",
    "            meridian = None\n",
    "            hr = int(hour)\n",
    "            if (hr >= 12):\n",
    "                if hr == 12:\n",
    "                    hour = str(12)\n",
    "                else:\n",
    "                    hour = str(hr - 12)\n",
    "                meridian = \"PM\"\n",
    "            else:\n",
    "                if hr == 0:\n",
    "                    hour = str(12)\n",
    "                else:\n",
    "                    hour = str(hr)\n",
    "                meridian = \"AM\"\n",
    "            data[i] = f\"{hour}-{min}-{sec} {meridian}\"\n",
    "        else:\n",
    "            data[i] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "time_data = ['032717', '202652', np.nan, '052735', '003419']\n",
    "print(\"\\n\\n.............IN STANDARD TIME FORMAT...........\\n\\n\")\n",
    "print(time_modifier(time_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW CLEANING THE DATA FROM THE CDR SHEET\n",
    "\n",
    "dataset_name = \"raw_cdr_data.csv\"\n",
    "dataframe = pd.read_csv(dataset_name, header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............REPLACING SIMPLE TERMINOLOGY WITH STANDARD TERMS...........\n",
      "\n",
      "\n",
      "['Outgoing' 'Incoming' nan]\n",
      "[nan 'Voice Portal']\n",
      "['Secondary Device' 'Primary Device' nan '6102632279@voip.evolveip.net'\n",
      " '6102632279.3@voip.evolveip.net' '6102300185.2@voip.evolveip.net'\n",
      " '6102634233@voip.evolveip.net' 'BroadWorks Anywhere' '+12167770642'\n",
      " '8474633614@voip.evolveip.net' '6102634118@voip.evolveip.net'\n",
      " '4843940092@voip.evolveip.net' '3306224638.3@voip.evolveip.net'\n",
      " '6102300215.uc.ucp@voip.evolveip.net' '6102634230@voip.evolveip.net'\n",
      " '5854217091.1@voip.evolveip.net' '4843940107.5@voip.evolveip.net'\n",
      " '4845880779@voip.evolveip.net' '6102320565@voip.evolveip.net'\n",
      " '6102321825@voip.evolveip.net' '6102634238@voip.evolveip.net'\n",
      " 'jthompson@eip.local' '2166060566@voip.evolveip.net'\n",
      " '6102321485@voip.evolveip.net' '4843940105@voip.evolveip.net'\n",
      " '4845880772@voip.evolveip.net' '4804092704@voip.evolveip.net']\n"
     ]
    }
   ],
   "source": [
    "# REPLACING SIMPLE TERMINOLOGY WITH STANDARD TERMS\n",
    "\n",
    "def replacing_simple_teminology_with_standard(dataframe):\n",
    "    dataframe[5] = dataframe[5].replace('Originating', 'Outgoing')\n",
    "    dataframe[5] = dataframe[5].replace('Terminating', 'Incoming')\n",
    "    dataframe[267] = dataframe[267].replace('Success', 'Voice Portal')\n",
    "    dataframe[312] = dataframe[312].replace('Shared Call Appearance', 'Secondary Device')\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "dataframe = replacing_simple_teminology_with_standard(dataframe)\n",
    "print(\"\\n\\n.............REPLACING SIMPLE TERMINOLOGY WITH STANDARD TERMS...........\\n\\n\")\n",
    "print(dataframe[5].unique())\n",
    "print(dataframe[267].unique())\n",
    "print(dataframe[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............REMOVING UNWANTED TERMS FROM COLUMN 312...........\n",
      "\n",
      "\n",
      "['Secondary Device' 'Primary Device' nan]\n"
     ]
    }
   ],
   "source": [
    "# REMOVING UNWANTED DATA FROM CDR SHEET\n",
    "\n",
    "def remove_unwanted_data(datacolumn):\n",
    "    for i in range(len(datacolumn)):\n",
    "        if datacolumn[i] == ('Secondary Device') or datacolumn[i] == ('Primary Device'):\n",
    "            continue\n",
    "        else:\n",
    "            datacolumn[i] = np.nan\n",
    "    return datacolumn\n",
    "\n",
    "\n",
    "dataframe[312] = remove_unwanted_data(dataframe[312].tolist())\n",
    "print(\"\\n\\n.............REMOVING UNWANTED TERMS FROM COLUMN 312...........\\n\\n\")\n",
    "print(dataframe[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".............COMBINING ALL THE SERVICES IN COL 312,147,267...........\n",
      "\n",
      "\n",
      "['Secondary Device' 'Primary Device' nan 'Call Forward No Answer'\n",
      " 'Hunt Group' 'Simultaneous Ring Personal' 'BroadWorks Anywhere Location'\n",
      " 'Call Forward Always' 'Remote Office' 'Push Notification Retrieval'\n",
      " 'Directed Call Pickup' 'Fax Deposit' 'Call Forward Busy'\n",
      " 'Primary Device , Voice Portal' 'Barge-in'\n",
      " 'Secondary Device , Voice Portal' 'Call Park'\n",
      " 'BroadWorks Anywhere Portal' 'Call Retrieve' 'Call Park Retrieve'\n",
      " '51380721939:0']\n"
     ]
    }
   ],
   "source": [
    "# COMBINIG ALL THE SERVICES\n",
    "\n",
    "def combine_all_services(datacolumn147, datacolumn312, datacolumn267):\n",
    "    for index in range(len(datacolumn147)):\n",
    "        if (datacolumn147[index] is np.nan):\n",
    "            if (datacolumn312[index] is not np.nan and datacolumn267[index] is not np.nan):\n",
    "                datacolumn147[index] = str(datacolumn312[index]) + \" , \" + str(datacolumn267[index])\n",
    "            elif (datacolumn312[index] is not np.nan):\n",
    "                datacolumn147[index] = datacolumn312[index]\n",
    "            else:\n",
    "                datacolumn147[index] = datacolumn267[index]\n",
    "        else:\n",
    "            continue\n",
    "    return datacolumn147\n",
    "\n",
    "\n",
    "dataframe[147] = combine_all_services(dataframe[147].tolist(), dataframe[312].tolist(), dataframe[267].tolist())\n",
    "print(\"\\n\\n.............COMBINING ALL THE SERVICES IN COL 312,147,267...........\\n\\n\")\n",
    "print(dataframe[147].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...........CONVERT DATE-TIME DATA INTO SPCIFIC FORMAT............\n",
      "\n",
      "\n",
      "['2019-06-20  03:27:18', '2019-06-21  13:28:20', nan, '2019-06-25  19:23:52']\n"
     ]
    }
   ],
   "source": [
    "# CONVERT DATE-TIME DATA INTO SPCIFIC FORMAT\n",
    "def call_time_fetcher(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            year = data[index][0:4]\n",
    "            month = data[index][4:6]\n",
    "            day = data[index][6:8]\n",
    "            hour = data[index][8:10]\n",
    "            minute = data[index][10:12]\n",
    "            seconds = str(round(float(data[index][12:])))\n",
    "\n",
    "            if int(seconds) >= 60:\n",
    "                seconds = int(seconds) - 60\n",
    "                minute = int(minute) + 1\n",
    "            if int(minute) >= 60:\n",
    "                minute = int(minute) - 1\n",
    "                hour = int(hour) + 1\n",
    "            data[index] = f\"{year}-{month}-{day}  {hour}:{minute}:{seconds}\"\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [\"20190620032717.906\", \"20190621132819.68\", 'nan', \"20190625192352.293\"]\n",
    "print(\"\\n\\n...........CONVERT DATE-TIME DATA INTO SPCIFIC FORMAT............\\n\\n\")\n",
    "print(call_time_fetcher(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...........FINDING HOURLY RANGE............\n",
      "\n",
      "\n",
      "['3:00 - 3:59', '13:00 - 13:59', nan, '19:00 - 19:59', '0:00 - 0:59', '12:00 - 12:59']\n"
     ]
    }
   ],
   "source": [
    "# FINDING THE HOURLY RANGE\n",
    "def hourly_range(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            if re.search(\"PM\", data[index]):\n",
    "                time_data = re.findall(\"\\d+\", data[index])\n",
    "                if time_data[0] != \"12\":\n",
    "                    time_data = int(time_data[0]) + 12\n",
    "                else:\n",
    "                    time_data = time_data[0]\n",
    "            else:\n",
    "                time_data = re.findall(\"\\d+\", data[index])\n",
    "                if time_data[0] == \"12\":\n",
    "                    time_data = int(time_data[0]) - 12\n",
    "                else:\n",
    "                    time_data = time_data[0]\n",
    "            data[index] = f\"{time_data}:00 - {time_data}:59\"\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['3:27:17 AM', '1:28:19 PM', 'nan', '7:23:52 PM', '12:20:45 AM', '12:56:27 PM']\n",
    "print(\"\\n\\n...........FINDING HOURLY RANGE............\\n\\n\")\n",
    "print(hourly_range(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...........FINDING WEEKLY RANGE............\n",
      "\n",
      "\n",
      "['Thursday', 'Friday', nan, 'Tuesday', 'Friday']\n"
     ]
    }
   ],
   "source": [
    "# FINDING THE WEEKLY RANGE\n",
    "def weekly_range(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = str(data[index])\n",
    "        if data[index] != \"nan\":\n",
    "            year, month, date = (int(x) for x in data[index].split(\"-\"))\n",
    "            result = datetime.date(year, month, date)\n",
    "            data[index] = result.strftime(\"%A\")\n",
    "        else:\n",
    "            data[index] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = ['2019-06-20', '2019-06-21', 'nan', '2019-06-25', '2020-11-06']\n",
    "print(\"\\n\\n...........FINDING WEEKLY RANGE............\\n\\n\")\n",
    "print(weekly_range(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Number of functions made\n",
    "1. datetime_divider()\n",
    "2. date_modifier()\n",
    "3. time_modifier()\n",
    "4. replacing_simple_teminology_with_standard()\n",
    "5. remove_unwanted_data()\n",
    "6. combine_all_services()\n",
    "7. call_time_fetcher()\n",
    "8. hourly_range()\n",
    "9. weekly_range()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...........NOW CREATING NEW COLUMNS WITH CLEANED DATA............\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n...........NOW CREATING NEW COLUMNS WITH CLEANED DATA............\\n\\n\")\n",
    "dataset_name = \"raw_cdr_data.csv\"\n",
    "raw_cdr_data = pd.read_csv(dataset_name, header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190620\n",
      "032717\n",
      "2019-06-20\n",
      "3-27-17 AM\n"
     ]
    }
   ],
   "source": [
    "# CREATE 2 COLUMNS TO STORE DATE AND TIME\n",
    "raw_cdr_data['date'], raw_cdr_data['time'] = zip(*datetime_divider(raw_cdr_data[9].tolist()))\n",
    "\n",
    "print(raw_cdr_data['date'].tolist()[0])\n",
    "print(raw_cdr_data['time'].tolist()[0])\n",
    "\n",
    "raw_cdr_data['date'] = date_modifier(raw_cdr_data['date'].tolist())\n",
    "raw_cdr_data['time'] = time_modifier(raw_cdr_data['time'].tolist())\n",
    "\n",
    "print(raw_cdr_data['date'].tolist()[0])\n",
    "print(raw_cdr_data['time'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Outgoing\n",
      "1        Incoming\n",
      "2        Outgoing\n",
      "3        Incoming\n",
      "4        Outgoing\n",
      "           ...   \n",
      "16733    Incoming\n",
      "16734    Outgoing\n",
      "16735    Incoming\n",
      "16736    Incoming\n",
      "16737    Incoming\n",
      "Name: 5, Length: 16738, dtype: object\n",
      "[nan 'Voice Portal']\n",
      "0        Secondary Device\n",
      "1          Primary Device\n",
      "2          Primary Device\n",
      "3          Primary Device\n",
      "4        Secondary Device\n",
      "               ...       \n",
      "16733                 NaN\n",
      "16734                 NaN\n",
      "16735                 NaN\n",
      "16736      Primary Device\n",
      "16737    Secondary Device\n",
      "Name: 312, Length: 16738, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# MAKING A NEW COLUMN WITH STANDARD TERMINOLOGIES\n",
    "raw_cdr_data = replacing_simple_teminology_with_standard(raw_cdr_data)\n",
    "print(raw_cdr_data[5])\n",
    "print(raw_cdr_data[267].unique())\n",
    "print(raw_cdr_data[312])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Secondary Device' 'Primary Device' nan]\n"
     ]
    }
   ],
   "source": [
    "# NOW REMOVING UNWANTED DATA FROM 312\n",
    "raw_cdr_data[312] = remove_unwanted_data(raw_cdr_data[312].tolist())\n",
    "print(raw_cdr_data[312].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Secondary Device' 'Primary Device' nan 'Call Forward No Answer'\n",
      " 'Hunt Group' 'Simultaneous Ring Personal' 'BroadWorks Anywhere Location'\n",
      " 'Call Forward Always' 'Remote Office' 'Push Notification Retrieval'\n",
      " 'Directed Call Pickup' 'Fax Deposit' 'Call Forward Busy'\n",
      " 'Primary Device , Voice Portal' 'Barge-in'\n",
      " 'Secondary Device , Voice Portal' 'Call Park'\n",
      " 'BroadWorks Anywhere Portal' 'Call Retrieve' 'Call Park Retrieve'\n",
      " '51380721939:0']\n"
     ]
    }
   ],
   "source": [
    "# NOW COMBINING DATA OF COLUMN 312 , 267 , 147\n",
    "raw_cdr_data[147] = combine_all_services(raw_cdr_data[147].tolist(), raw_cdr_data[312].tolist(), raw_cdr_data[267].tolist())\n",
    "print(raw_cdr_data[147].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019-06-20 03:27:18\n",
      "1       2019-06-20 03:27:18\n",
      "2       2019-06-20 05:26:53\n",
      "3       2019-06-20 05:27:35\n",
      "4       2019-06-20 06:04:35\n",
      "                ...        \n",
      "16733   2019-06-25 19:23:34\n",
      "16734   2019-06-25 19:23:52\n",
      "16735   2019-06-25 19:23:52\n",
      "16736   2019-06-25 19:24:06\n",
      "16737   2019-06-25 19:21:43\n",
      "Name: starttime, Length: 16738, dtype: datetime64[ns]\n",
      "0       2019-06-20 04:04:27\n",
      "1       2019-06-20 04:04:27\n",
      "2       2019-06-20 05:27:09\n",
      "3       2019-06-20 06:01:25\n",
      "4       2019-06-20 06:06:16\n",
      "                ...        \n",
      "16733   2019-06-25 19:23:55\n",
      "16734   2019-06-25 19:23:55\n",
      "16735   2019-06-25 19:23:55\n",
      "16736   2019-06-25 19:24:27\n",
      "16737   2019-06-25 19:24:54\n",
      "Name: endtime, Length: 16738, dtype: datetime64[ns]\n",
      "0        37.0\n",
      "1        37.0\n",
      "2         0.0\n",
      "3        33.0\n",
      "4         1.0\n",
      "         ... \n",
      "16733     0.0\n",
      "16734     0.0\n",
      "16735     0.0\n",
      "16736     0.0\n",
      "16737     3.0\n",
      "Name: duration, Length: 16738, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# NOW MAKING 2 TEMPORARY COLUMNS FOR CALCULATING THE CALL DURATION\n",
    "raw_cdr_data['starttime'] = pd.to_datetime(call_time_fetcher(raw_cdr_data[9].tolist()))\n",
    "print(raw_cdr_data['starttime'])\n",
    "raw_cdr_data['endtime'] = pd.to_datetime(call_time_fetcher(raw_cdr_data[13].tolist()))\n",
    "print(raw_cdr_data['endtime'])\n",
    "\n",
    "raw_cdr_data[\"duration\"] = (raw_cdr_data[\"endtime\"] - raw_cdr_data[\"starttime\"]).astype(\"timedelta64[m]\")\n",
    "print(raw_cdr_data[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          3:00 - 3:59\n",
      "1          3:00 - 3:59\n",
      "2          5:00 - 5:59\n",
      "3          5:00 - 5:59\n",
      "4          6:00 - 6:59\n",
      "             ...      \n",
      "16733    19:00 - 19:59\n",
      "16734    19:00 - 19:59\n",
      "16735    19:00 - 19:59\n",
      "16736    19:00 - 19:59\n",
      "16737    19:00 - 19:59\n",
      "Name: hourly_range, Length: 16738, dtype: object\n",
      "0        Thursday\n",
      "1        Thursday\n",
      "2        Thursday\n",
      "3        Thursday\n",
      "4        Thursday\n",
      "           ...   \n",
      "16733     Tuesday\n",
      "16734     Tuesday\n",
      "16735     Tuesday\n",
      "16736     Tuesday\n",
      "16737     Tuesday\n",
      "Name: weekly_range, Length: 16738, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# NOW CREATING 2 COLUMNS FOR HOURLY RANGE AND WEEKLY RANGE\n",
    "raw_cdr_data['hourly_range'] = hourly_range(raw_cdr_data['time'].tolist())\n",
    "print(raw_cdr_data['hourly_range'])\n",
    "\n",
    "raw_cdr_data['weekly_range'] = weekly_range(raw_cdr_data['date'].tolist())\n",
    "print(raw_cdr_data['weekly_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE THE COLUMNS WHICH ARE NOT REQUIRED\n",
    "raw_cdr_data = raw_cdr_data.drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cdr_data.csv\"\n",
    "\n",
    "# Required columns\n",
    "call_columns = [\"4\", \"5\", \"14\", \"31\", \"120\", \"147\", \"267\", \"312\", \"345\", \\\n",
    "                \"date\", \"starttime\", \"endtime\", \"duration\", \"hourly_range\", \"weekly_range\"]\n",
    "\n",
    "call_dataset = pd.read_csv(dataset_name, usecols=call_columns, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR SERVICE DATA\n",
    "service_columns = ['31', '120', '147', '345', 'date', 'starttime', 'endtime', 'duration']\n",
    "service_dataset = call_dataset[service_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR DEVICE DATASET\n",
    "device_columns = ['5', '31', '120', '312', '345', 'date', 'starttime', 'endtime', 'duration']\n",
    "device_dataset = call_dataset[device_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL THE CSV FILES ARE CREATED SUCCESSFULLY..........!!!!!\n"
     ]
    }
   ],
   "source": [
    "# RENAMING COLUMN NAMES AS PER CLIENT REQUIREMENT\n",
    "call_dataset = call_dataset.rename(columns={\"4\": \"Group\", \"5\": \"Call_Direction\", \"14\": \"Missed Calls\",\n",
    "                                            \"31\": \"GroupID\", \"120\": \"UserID\", \"147\": \"Features\",\n",
    "                                            \"267\": \" vpDialingfacResult\",\n",
    "                                            \"312\": \"UsageDeviceType\",\n",
    "                                            \"345\": \"UserDeviceType\"})\n",
    "\n",
    "service_dataset = service_dataset.rename(columns={\"120\": \"UserID\",\n",
    "                                                  \"31\": \"GroupID\", \"147\": \"FeatureName\",\n",
    "                                                  \"345\": \"UserDeviceType\", \"date\": \"FeatureEventDate\"\n",
    "                                                  })\n",
    "\n",
    "device_dataset = device_dataset.rename(columns={\"5\": \"DeviceEventTypeDirection\",\n",
    "                                                \"120\": \"UserID\", \"31\": \"GroupID\",\n",
    "                                                \"345\": \"UserDeviceType\", \"date\": \"DeviceEventDate\",\n",
    "                                                \"312\": \"UsageDeviceType\"})\n",
    "\n",
    "call_dataset.to_csv(\"Call_data.csv\", index=None)\n",
    "service_dataset.to_csv(\"Service_data.csv\", index=None)\n",
    "device_dataset.to_csv(\"Device_data.csv\", index=None)\n",
    "print(\"ALL THE CSV FILES ARE CREATED SUCCESSFULLY..........!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
